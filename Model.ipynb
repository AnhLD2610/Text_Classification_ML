{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import TextEmbedding \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open('D:\\ML_project\\datatest\\X_train.pkl', 'rb'))\n",
    "X_test = pickle.load(open('D:\\ML_project\\datatest\\X_test.pkl', 'rb'))\n",
    "y_train = pickle.load(open('D:\\ML_project\\datatest\\y_train.pkl', 'rb'))\n",
    "y_test = pickle.load(open('D:\\ML_project\\datatest\\y_test.pkl', 'rb'))\n",
    "\n",
    "doc2vec_embedding, test_embedding = TextEmbedding.tfidf(X_train,X_test)\n",
    "print(doc2vec_embedding[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic ={\n",
    "    \"thoi-su\": 0,\n",
    "    \"kinh-doanh\": 1,\n",
    "    \"khoa-hoc\": 2,\n",
    "    \"giai-tri\": 3,\n",
    "    \"the-thao\": 4,\n",
    "    \"phap-luat\": 5, \n",
    "    \"giao-duc\": 6,\n",
    "    \"suc-khoe\": 7,\n",
    "    \"doi-song\": 8,\n",
    "    \"du-lich\":  9\n",
    "}\n",
    "for i in range (len(y_train)):\n",
    "    for x, y in list_topic.items():\n",
    "        if y_train[i] == x:\n",
    "            y_train[i] = y \n",
    "for i in range (len(y_test)):\n",
    "    for x, y in list_topic.items():\n",
    "        if y_test[i] == x:\n",
    "            y_test[i] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(X_train, y_train, X_test, y_test, kernel, C):\n",
    "    C = 1.0  # SVM regularization parameter\n",
    "    #svc = LinearSVC(C=C).fit(embedding_array, y_train)\n",
    "    # rbf_svc = SVC(kernel='rbf', C=10).fit(doc2vec_embedding, y_train)\n",
    "    rbf_svc = SVC(kernel='poly', degree=3, C=C).fit(doc2vec_embedding, y_train)\n",
    "    test_predictions = rbf_svc.predict(test_embedding)\n",
    "    cf = confusion_matrix(y_test, test_predictions)\n",
    "    \n",
    "    f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "    recall = recall_score(y_test, test_predictions, average='micro')\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    return accuracy, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    rdf = RandomForestClassifier(n_estimators=1000, max_depth=30, random_state=0)\n",
    "    rdf.fit(doc2vec_embedding, y_train)\n",
    "    test_predictions = rdf.predict(test_embedding)\n",
    "    f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "    recall = recall_score(y_test, test_predictions, average='micro')\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    return accuracy, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, y_train, X_test, y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "    neigh.fit(doc2vec_embedding, y_train)\n",
    "    test_predictions = neigh.predict(test_embedding)\n",
    "    f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "    recall = recall_score(y_test, test_predictions, average='micro')\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    return accuracy, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, activation = 'relu', input_shape = X_train[0]))\n",
    "    model.add(Dense(10, activation = 'sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    # Cross-Entropy Loss (Log Loss)\n",
    "    # Categorical Hinge Loss\n",
    "    # metrics = accuracy \n",
    "    model.compile(optimizer='adam',learning_rate = 10, loss= \"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "    model.summary()\n",
    "    history = model.fit(X_train, y_train, batch_size = 32, epochs = 20, verbose = 1)\n",
    "\n",
    "    # Test the model after training\n",
    "    test_results = model.evaluate(test_embedding, y_test, verbose=1)\n",
    "    f1 = f1_score(y_test, test_results, average='micro')\n",
    "    recall = recall_score(y_test, test_results, average='micro')\n",
    "    accuracy = accuracy_score(y_test, test_results)\n",
    "    print(f'Test results - Loss: {test_results[0]} - Accuracy: {100*test_results[1]}%')\n",
    "    \n",
    "    return accuracy, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchCV_SVM():\n",
    "    params = dict()\n",
    "    param_grid = {\n",
    "        # 'C': [0.1, 1, 10, 100],\n",
    "        # # 'gamma': [0.1, 0.01, 0.001],\n",
    "        # 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        'C': [1, 10],\n",
    "        # # 'gamma': [0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "    f1_scorer = make_scorer(f1_score, average='micro')\n",
    "    recall_scorer = make_scorer(recall_score, average='micro')\n",
    "    svm_model = SVC()\n",
    "    grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "    grid_search.fit(doc2vec_embedding, y_train)\n",
    "\n",
    "    print(grid_search.cv_results_['mean_test_score'])\n",
    "    print(grid_search.cv_results_['params'])\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= f1_scorer, cv=5)\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= recall_scorer, cv=5)\n",
    "\n",
    "    \n",
    "    # grid_search.fit(doc2vec_embedding, y_train)\n",
    "    # print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    # print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "    # accuracy = grid_search.score(X_test, y_test)\n",
    "    # print(\"Test Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_KNN():\n",
    "    grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "    #Since we have provided the class validation score as 3( cv= 3),\n",
    "    # Grid Search will evaluate the model 6 x 2 x 3 x 3 = 108 times with different hyperparameters.\n",
    "    gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "    g_res = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_RandomForest():\n",
    "    param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "    rf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                            cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(units=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def GridSearch_LSTM(X_train, y_train, units=50):\n",
    "    lstm_model = KerasClassifier(build_fn=create_lstm_model, units=units, verbose=1)\n",
    "\n",
    "    parameters = {'units': [200, 100, 150], 'batch_size': [32, 64, 128], 'epochs': [10, 20]}\n",
    "    grid_search = GridSearchCV(estimator=lstm_model, param_grid=parameters, scoring=make_scorer(accuracy_score), cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and score\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "    return 1\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)\n",
    "GridSearch_LSTM(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(parameters, mean_validation_score):\n",
    "    # Extract the parameter values and scores\n",
    "    param_values = parameters\n",
    "    scores = mean_validation_score\n",
    "\n",
    "    # Sort the scores and parameter values based on the scores\n",
    "    sorted_indices = np.argsort(scores)\n",
    "    sorted_scores = np.array(scores)[sorted_indices]\n",
    "    sorted_params = np.array(param_values)[sorted_indices]\n",
    "\n",
    "    # Plot the scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sorted_scores, 'o-')\n",
    "    plt.ylabel('Mean Validation Score')\n",
    "    plt.title('Grid Search Results')\n",
    "\n",
    "    # Set x-axis labels as parameter-value pairs\n",
    "    x_labels = ['\\n'.join([f'{param}: {value}' for param, value in param_set.items()]) for param_set in sorted_params]\n",
    "    plt.xticks(range(len(sorted_params)), x_labels, rotation=0, ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020 files randomly selected and copied to D:/ML_project/FinalData/doi-song.\n",
      "1071 files randomly selected and copied to D:/ML_project/FinalData/du-lich.\n",
      "1054 files randomly selected and copied to D:/ML_project/FinalData/giai-tri.\n",
      "1083 files randomly selected and copied to D:/ML_project/FinalData/giao-duc.\n",
      "1042 files randomly selected and copied to D:/ML_project/FinalData/khoa-hoc.\n",
      "1034 files randomly selected and copied to D:/ML_project/FinalData/kinh-doanh.\n",
      "1023 files randomly selected and copied to D:/ML_project/FinalData/phap-luat.\n",
      "1027 files randomly selected and copied to D:/ML_project/FinalData/suc-khoe.\n",
      "1066 files randomly selected and copied to D:/ML_project/FinalData/the-thao.\n",
      "1058 files randomly selected and copied to D:/ML_project/FinalData/thoi-su.\n"
     ]
    }
   ],
   "source": [
    "# copy 1000 file dau tu folder này sang folder khác \n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "num_files = [1020, 1071, 1054, 1083, 1042, 1034, 1023, 1027, 1066, 1058]\n",
    "lst = ['doi-song','du-lich','giai-tri','giao-duc','khoa-hoc','kinh-doanh','phap-luat','suc-khoe','the-thao','thoi-su']\n",
    "for i in range(10):\n",
    "    # Path to the folder containing files\n",
    "    folder_path = \"D:/ML_project/data - Copy/\" + lst[i]\n",
    "\n",
    "    # Number of files to select randomly\n",
    "    # List all files in the folder\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # Shuffle the file list randomly\n",
    "    random.shuffle(file_list)\n",
    "\n",
    "    # Create a new folder to store the selected files\n",
    "    output_folder = \"D:/ML_project/FinalData/\" + lst[i]\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Select the first 'num_files' files from the shuffled list\n",
    "    selected_files = file_list[:num_files[i]]\n",
    "\n",
    "    # Copy the selected files to the output folder\n",
    "    for file_name in selected_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        shutil.copy(file_path, output_path)\n",
    "\n",
    "    print(f\"{num_files[i]} files randomly selected and copied to {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1020, 1000, 1054, 1083, 1012, 1004, 1023, 1027, 1006, 1058]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_numbers = random.sample(range(1000, 1101), 10)\n",
    "print(random_numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
