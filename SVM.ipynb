{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import TextEmbedding \n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open('FinalData\\X_train.pkl', 'rb'))\n",
    "X_test = pickle.load(open('FinalData\\X_test.pkl', 'rb'))\n",
    "y_train = pickle.load(open('FinalData\\y_train.pkl', 'rb'))\n",
    "y_test = pickle.load(open('FinalData\\y_test.pkl', 'rb'))\n",
    "\n",
    "X_train_w2v = pickle.load(open('FinalData\\X_train_w2v.pkl', 'rb'))\n",
    "X_test_w2v = pickle.load(open('FinalData\\X_test_w2v.pkl', 'rb'))\n",
    "y_train_w2v = pickle.load(open('FinalData\\y_train_w2v.pkl', 'rb'))\n",
    "y_test_w2v = pickle.load(open('FinalData\\y_test_w2v.pkl', 'rb'))\n",
    "tfidf_embedding_train, tfidf_embedding_test = TextEmbedding.tfidf(X_train,X_test)\n",
    "BOW_embedding_train, BOW_embedding_test = TextEmbedding.BagOfWord(X_train,X_test)\n",
    "w2v_embedding_train, w2v_embedding_test = TextEmbedding.Word2Vector(X_train,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic ={\n",
    "    \"thoi-su\": 0,\n",
    "    \"kinh-doanh\": 1,\n",
    "    \"khoa-hoc\": 2,\n",
    "    \"giai-tri\": 3,\n",
    "    \"the-thao\": 4,\n",
    "    \"phap-luat\": 5, \n",
    "    \"giao-duc\": 6,\n",
    "    \"suc-khoe\": 7,\n",
    "    \"doi-song\": 8,\n",
    "    \"du-lich\":  9\n",
    "}\n",
    "for i in range (len(y_train)):\n",
    "    for x, y in list_topic.items():\n",
    "        if y_train[i] == x:\n",
    "            y_train[i] = y \n",
    "for i in range (len(y_test)):\n",
    "    for x, y in list_topic.items():\n",
    "        if y_test[i] == x:\n",
    "            y_test[i] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(X_train, y_train, X_test, y_test, kernel, C):\n",
    "   \n",
    "    svc = SVC(kernel=kernel, degree=3, C=C).fit(X_train, y_train)\n",
    "    test_predictions = svc.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "    recall = recall_score(y_test, test_predictions, average='macro')\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    return accuracy, recall, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET BEST SET OF PARAMETERS (USING BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['rbf', 'linear', 'poly', 'sigmoid']  \n",
    "accuracy_values = []\n",
    "recall_values = []\n",
    "f1_values = []\n",
    "\n",
    "for value in values:\n",
    "    accuracy, recall, f1 = SVC(BOW_embedding_train, y_train, BOW_embedding_test, y_test, value, 1)\n",
    "    accuracy_values.append(accuracy)\n",
    "    recall_values.append(recall)\n",
    "    f1_values.append(f1)\n",
    "\n",
    "\n",
    "bar_width = 0.2\n",
    "print(accuracy_values)\n",
    "print(recall_values)\n",
    "print(f1_values)\n",
    "\n",
    "bar_positions = np.arange(len(values))\n",
    "\n",
    "plt.bar(bar_positions, accuracy_values, width=bar_width, color='red', label='Accuracy')\n",
    "plt.bar(bar_positions + bar_width, recall_values, width=bar_width, color='blue', label='Recall')\n",
    "plt.bar(bar_positions + 2*bar_width, f1_values, width=bar_width, color='green', label='F1 Score')\n",
    "\n",
    "plt.xlabel('kernel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('SVM performance with C = 1')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.22), ncol=3)\n",
    "\n",
    "plt.xticks(bar_positions + bar_width, values)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search(param, list_params, result):\n",
    "    values = [params[param] for params in list_params]\n",
    "\n",
    "    accuracy_values = result\n",
    "\n",
    "    bar_width = 0.2\n",
    "    \n",
    "\n",
    "    bar_positions = np.arange(len(values))\n",
    "\n",
    "    plt.bar(bar_positions, accuracy_values, width=bar_width, color='red', label='Accuracy')\n",
    "\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('SVM Performance Accuracy with kernel = sigmoid')\n",
    "    plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.22), ncol=3)\n",
    "\n",
    "    plt.xticks(bar_positions, values)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchCV_SVM():\n",
    "    param_grid = {\n",
    "        # 'C': [0.1, 1, 10, 100],\n",
    "        # # 'gamma': [0.1, 0.01, 0.001],\n",
    "        # 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        'C': [0.01, 0.1, 1, 2, 5, 10, 100],\n",
    "    }\n",
    "    # f1_scorer = make_scorer(f1_score, average='micro')\n",
    "    # recall_scorer = make_scorer(recall_score, average='micro')\n",
    "    svm_model = SVC(kernel='sigmoid')\n",
    "    grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "    grid_search.fit(BOW_embedding_train , y_train)\n",
    "\n",
    "    print(grid_search.cv_results_['mean_test_score'])\n",
    "    print(grid_search.cv_results_['params'])\n",
    "    plot_grid_search('C', grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score'])\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= f1_scorer, cv=5)\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= recall_scorer, cv=5)\n",
    "\n",
    "GridSearchCV_SVM()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET BEST SET OF PARAMETERS (USING TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['rbf', 'linear', 'poly', 'sigmoid']  \n",
    "accuracy_values = []\n",
    "recall_values = []\n",
    "f1_values = []\n",
    "\n",
    "for value in values:\n",
    "    accuracy, recall, f1 = SVC(tfidf_embedding_train, y_train, tfidf_embedding_test, y_test, value, 1)\n",
    "    accuracy_values.append(accuracy)\n",
    "    recall_values.append(recall)\n",
    "    f1_values.append(f1)\n",
    "\n",
    "\n",
    "bar_width = 0.2\n",
    "print(accuracy_values)\n",
    "print(recall_values)\n",
    "print(f1_values)\n",
    "\n",
    "bar_positions = np.arange(len(values))\n",
    "\n",
    "plt.bar(bar_positions, accuracy_values, width=bar_width, color='red', label='Accuracy')\n",
    "plt.bar(bar_positions + bar_width, recall_values, width=bar_width, color='blue', label='Recall')\n",
    "plt.bar(bar_positions + 2*bar_width, f1_values, width=bar_width, color='green', label='F1 Score')\n",
    "\n",
    "plt.xlabel('kernel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('SVM performance with C = 1')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.22), ncol=3)\n",
    "\n",
    "plt.xticks(bar_positions + bar_width, values)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search(param, list_params, result):\n",
    "    values = [params[param] for params in list_params]\n",
    "\n",
    "    accuracy_values = result\n",
    "\n",
    "    bar_width = 0.2\n",
    "    \n",
    "\n",
    "    bar_positions = np.arange(len(values))\n",
    "\n",
    "    plt.bar(bar_positions, accuracy_values, width=bar_width, color='red', label='Accuracy')\n",
    "\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('SVM Performance Accuracy with kernel = sigmoid')\n",
    "    plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.22), ncol=3)\n",
    "\n",
    "    plt.xticks(bar_positions, values)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchCV_SVM():\n",
    "    param_grid = {\n",
    "        # 'C': [0.1, 1, 10, 100],\n",
    "        # # 'gamma': [0.1, 0.01, 0.001],\n",
    "        # 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        'C': [0.01, 0.1, 1, 2, 5, 10, 100],\n",
    "    }\n",
    "    # f1_scorer = make_scorer(f1_score, average='micro')\n",
    "    # recall_scorer = make_scorer(recall_score, average='micro')\n",
    "    svm_model = SVC(kernel='sigmoid')\n",
    "    grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "    grid_search.fit(tfidf_embedding_train , y_train)\n",
    "\n",
    "    print(grid_search.cv_results_['mean_test_score'])\n",
    "    print(grid_search.cv_results_['params'])\n",
    "    plot_grid_search('C', grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score'])\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= f1_scorer, cv=5)\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= recall_scorer, cv=5)\n",
    "\n",
    "GridSearchCV_SVM()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET BEST SET OF PARAMETERS (USING WORD2VEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['rbf', 'linear', 'poly', 'sigmoid']  \n",
    "accuracy_values = []\n",
    "recall_values = []\n",
    "f1_values = []\n",
    "\n",
    "for value in values:\n",
    "    accuracy, recall, f1 = SVC(w2v_embedding_train, y_train, w2v_embedding_test, y_test, value, 1)\n",
    "    accuracy_values.append(accuracy)\n",
    "    recall_values.append(recall)\n",
    "    f1_values.append(f1)\n",
    "\n",
    "\n",
    "bar_width = 0.2\n",
    "print(accuracy_values)\n",
    "print(recall_values)\n",
    "print(f1_values)\n",
    "\n",
    "bar_positions = np.arange(len(values))\n",
    "\n",
    "plt.bar(bar_positions, accuracy_values, width=bar_width, color='red', label='Accuracy')\n",
    "plt.bar(bar_positions + bar_width, recall_values, width=bar_width, color='blue', label='Recall')\n",
    "plt.bar(bar_positions + 2*bar_width, f1_values, width=bar_width, color='green', label='F1 Score')\n",
    "\n",
    "plt.xlabel('kernel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('SVM performance with C = 1')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.22), ncol=3)\n",
    "\n",
    "plt.xticks(bar_positions + bar_width, values)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search(param, list_params, result):\n",
    "    values = [params[param] for params in list_params]\n",
    "\n",
    "    accuracy_values = result\n",
    "\n",
    "    bar_width = 0.2\n",
    "    \n",
    "\n",
    "    bar_positions = np.arange(len(values))\n",
    "\n",
    "    plt.bar(bar_positions, accuracy_values, width=bar_width, color='red', label='Accuracy')\n",
    "\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('SVM Performance Accuracy with kernel = sigmoid')\n",
    "    plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.22), ncol=3)\n",
    "\n",
    "    plt.xticks(bar_positions, values)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchCV_SVM():\n",
    "    param_grid = {\n",
    "        # 'C': [0.1, 1, 10, 100],\n",
    "        # # 'gamma': [0.1, 0.01, 0.001],\n",
    "        # 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        'C': [0.01, 0.1, 1, 2, 5, 10, 100],\n",
    "    }\n",
    "    # f1_scorer = make_scorer(f1_score, average='micro')\n",
    "    # recall_scorer = make_scorer(recall_score, average='micro')\n",
    "    svm_model = SVC(kernel='sigmoid')\n",
    "    grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "    grid_search.fit(tfidf_embedding_train , y_train)\n",
    "\n",
    "    print(grid_search.cv_results_['mean_test_score'])\n",
    "    print(grid_search.cv_results_['params'])\n",
    "    plot_grid_search('C', grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score'])\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= f1_scorer, cv=5)\n",
    "    # grid_search = GridSearchCV(svm_model, param_grid, scoring= recall_scorer, cv=5)\n",
    "\n",
    "GridSearchCV_SVM()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARE BOW, TFIDF, WORD2VEC WITH BEST OF SET PARAMETERS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
